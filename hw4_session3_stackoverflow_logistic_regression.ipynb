{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.3\n",
      "IPython 6.1.0\n",
      "\n",
      "numpy 1.13.3\n",
      "scipy 0.19.1\n",
      "pandas 0.20.3\n",
      "matplotlib 2.1.0\n",
      "sklearn 0.19.1\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)\n",
      "system     : Darwin\n",
      "release    : 16.6.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : f2f0756ee48c44675e0c2de5f40bdc4f37384dfc\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = 'datasets/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = 'datasets/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'html', 'php', 'c++', 'c#', 'javascript', 'android', 'ios', 'python', 'java', 'jquery'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "<font color=\"green\">\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "    </font>\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "<font color=\"green\">\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "</font>\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "#                 if n==10:\n",
    "#                     break\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = W_0\n",
    "                    z = self._b[tag]\n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        if z < 600 and z > -10000:\n",
    "                            z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ... log(1/ 1 + (e^Zi))\n",
    "                    sigma = 1/(1+np.exp(-z))\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss += -(y * np.log(np.maximum(sigma,tolerance)) + (1-y) * np.log(np.maximum((1-sigma),tolerance)))\n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b552b24a2044c3c9cdb38a2aead1341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:97: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-4130e000c684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# создадим эксемпляр модели и пройдемся по датасету\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-d3abdcc8eb3d>\u001b[0m in \u001b[0;36miterate_file\u001b[0;34m(self, fname, top_n_train, total, learning_rate, tolerance)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;31m# поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdLdw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdLdw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d0d2710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 19.24\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "<font color=\"green\">\n",
    "3. 19.74\n",
    "    </font>\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        self._acc = []\n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "#                 if n==10:\n",
    "#                     break\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                predicted_tags = []\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = W_0\n",
    "                    z = self._b[tag]\n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ... log(1/ 1 + (e^Zi))\n",
    "                    if z < -650:\n",
    "                        sigma = 0\n",
    "                    elif z > 650:\n",
    "                        sigma = 1\n",
    "                    else:\n",
    "                        sigma = 1/(1+np.exp(-z))\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss += -(y * np.log(np.maximum(sigma,tolerance)) + (1-y) * np.log(np.maximum((1-sigma),tolerance)))\n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if sigma > 0.9:\n",
    "                            predicted_tags.append(tag)\n",
    "                if n >= top_n_train:\n",
    "                    a = tags\n",
    "                    b = set(predicted_tags)\n",
    "                    self._acc.append(len(a&b)/len(a|b))\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "        return np.mean(self._acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cfd2786901449296d577260990b40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.58\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "<font color=\"green\">\n",
    "3. 0.59\n",
    "</font>\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16\n",
    "                     lmbda=0.01):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        self._acc = []\n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                predicted_tags = []\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = W_0\n",
    "                    z = self._b[tag]\n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ... log(1/ 1 + (e^Zi))\n",
    "                    if z < -650:\n",
    "                        sigma = 0\n",
    "                    elif z > 650:\n",
    "                        sigma = 1\n",
    "                    else:\n",
    "                        sigma = 1/(1+np.exp(-z))\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss += -(y * np.log(np.maximum(sigma,tolerance)) + (1-y) * np.log(np.maximum((1-sigma),tolerance)))\n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if sigma > 0.9:\n",
    "                            predicted_tags.append(tag)\n",
    "                if n >= top_n_train:\n",
    "                    a = tags\n",
    "                    b = set(predicted_tags)\n",
    "                    self._acc.append(len(a&b)/len(a|b))\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "        return np.mean(self._acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
